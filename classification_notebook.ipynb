{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffbcc2d",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d36b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from stop_words import get_stop_words\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84f163",
   "metadata": {},
   "source": [
    "# Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66ecd5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category                                              title  \\\n",
      "0   Polska  \"Prezydent jest na końcu łańcucha\". Siemoniak ...   \n",
      "1   Polska  Jarosław Sosnowski jak Tomasz Komenda? Siedzi ...   \n",
      "2   Polska  ZUS przesuwa terminy 800 plus. Sprawdź, kto do...   \n",
      "3   Polska  Dentysta wyłudził ponad 1,2 mln zł od NFZ. Zap...   \n",
      "4   Polska  Zderzenie tramwajów w Krakowie. Wielu poszkodo...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.polsatnews.pl/wiadomosc/2025-12-03...   \n",
      "1  https://www.polsatnews.pl/wiadomosc/2025-12-03...   \n",
      "2  https://www.polsatnews.pl/wiadomosc/2025-12-03...   \n",
      "3  https://www.polsatnews.pl/wiadomosc/2025-12-03...   \n",
      "4  https://www.polsatnews.pl/wiadomosc/2025-12-03...   \n",
      "\n",
      "                         published  \\\n",
      "0  Wed, 03 Dec 2025 20:15:00 +0100   \n",
      "1  Wed, 03 Dec 2025 20:09:00 +0100   \n",
      "2  Wed, 03 Dec 2025 19:46:00 +0100   \n",
      "3  Wed, 03 Dec 2025 19:43:00 +0100   \n",
      "4  Wed, 03 Dec 2025 18:36:00 +0100   \n",
      "\n",
      "                                                text  \\\n",
      "0  W środowym wydaniu programu \"Gość Wydarzeń\" To...   \n",
      "1  - Mamy do czynienia z niewinnym człowiekiem. O...   \n",
      "2  W grudniu Zakład Ubezpieczeń Społecznych wprow...   \n",
      "3  Miastecki stomatolog Bartłomiej S. stanął w śr...   \n",
      "4  W Krakowie przy ulicy Bieńczyckiej w środę oko...   \n",
      "\n",
      "                                           text_norm  \\\n",
      "0  środowy wydanie program gość wydarzenie tomasz...   \n",
      "1  mieć czynić niewinny człowiek rok siedzieć zak...   \n",
      "2  grudzień zakład ubezpieczenie społeczny wprowa...   \n",
      "3  miastecki stomatolog bartłomi stanąć środa sąd...   \n",
      "4  krakowie ulica bieńczycki środa godza dojść zd...   \n",
      "\n",
      "                                              tokens  n_tokens  \n",
      "0  ['środowy', 'wydanie', 'program', 'gość', 'wyd...       293  \n",
      "1  ['mieć', 'czynić', 'niewinny', 'człowiek', 'ro...       579  \n",
      "2  ['grudzień', 'zakład', 'ubezpieczenie', 'społe...       154  \n",
      "3  ['miastecki', 'stomatolog', 'bartłomi', 'staną...       382  \n",
      "4  ['krakowie', 'ulica', 'bieńczycki', 'środa', '...        90  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298 entries, 0 to 297\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   category   298 non-null    object\n",
      " 1   title      298 non-null    object\n",
      " 2   url        298 non-null    object\n",
      " 3   published  298 non-null    object\n",
      " 4   text       298 non-null    object\n",
      " 5   text_norm  298 non-null    object\n",
      " 6   tokens     298 non-null    object\n",
      " 7   n_tokens   298 non-null    int64 \n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 18.8+ KB\n",
      "None\n",
      "category\n",
      "Świat          50\n",
      "Biznes         50\n",
      "Technologie    50\n",
      "Moto           50\n",
      "Sport          50\n",
      "Polska         48\n",
      "Name: count, dtype: int64\n",
      "Total records: 298\n",
      "2k records are generally sufficient for a small neural network with balanced categories, but more data can improve performance.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Scrapper/polsatnews_articles_clean.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df['category'].value_counts())\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(\"2k records are generally sufficient for a small neural network with balanced categories, but more data can improve performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1d002",
   "metadata": {},
   "source": [
    "# Preprocess Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7867c91",
   "metadata": {},
   "source": [
    "Zainstaluj wymagane biblioteki: pip install -r requirements.txt. NLTK punkt zostanie pobrany automatycznie.\n",
    "\n",
    "**Dlaczego nie spaCy?** SpaCy ma znane problemy z kompilacją na macOS z procesorami M1/M2, powodując błędy takie jak '__reduce_cython__'. NLTK jest prostszą alternatywą, stabilną na tym sprzęcie, choć bez zaawansowanych funkcji jak lematyzacja. Dla polskiego tekstu używa podstawowych stopwords z biblioteki stop-words i tokenizacji z NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c752155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mptb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(get_stop_words('polish'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64062a19",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "986c4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['category'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356efec0",
   "metadata": {},
   "source": [
    "# Build Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74093c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = TextClassifier(X_train.shape[1], num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6da45",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22ca97df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.7896\n",
      "Epoch 2/10, Loss: 1.7220\n",
      "Epoch 3/10, Loss: 1.6324\n",
      "Epoch 4/10, Loss: 1.3838\n",
      "Epoch 5/10, Loss: 0.8426\n",
      "Epoch 6/10, Loss: 0.4035\n",
      "Epoch 7/10, Loss: 0.2291\n",
      "Epoch 8/10, Loss: 0.0930\n",
      "Epoch 9/10, Loss: 0.0676\n",
      "Epoch 10/10, Loss: 0.0281\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92131a",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8adfb867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Biznes       1.00      0.82      0.90        11\n",
      "        Moto       0.64      1.00      0.78         7\n",
      "      Polska       0.55      0.60      0.57        10\n",
      "       Sport       1.00      0.86      0.92         7\n",
      " Technologie       0.90      0.75      0.82        12\n",
      "       Świat       0.77      0.77      0.77        13\n",
      "\n",
      "    accuracy                           0.78        60\n",
      "   macro avg       0.81      0.80      0.79        60\n",
      "weighted avg       0.81      0.78      0.79        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, y_pred_classes = torch.max(outputs, 1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test.cpu().numpy(), y_pred_classes.cpu().numpy())}\")\n",
    "print(classification_report(y_test.cpu().numpy(), y_pred_classes.cpu().numpy(), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7113068",
   "metadata": {},
   "source": [
    "# Predict Categories on New Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d54de4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category: Polska\n"
     ]
    }
   ],
   "source": [
    "def predict_category(text):\n",
    "    processed = preprocess_text(text)\n",
    "    vectorized = vectorizer.transform([processed])\n",
    "    input_tensor = torch.tensor(vectorized.toarray(), dtype=torch.float32).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "    return label_encoder.inverse_transform(predicted_class.cpu().numpy())[0]\n",
    "\n",
    "new_article = \"Nowy prezydent został wybrany w wyborach.\"\n",
    "predicted_category = predict_category(new_article)\n",
    "print(f\"Predicted category: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a08a2b",
   "metadata": {},
   "source": [
    "# Simple Web Application with Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deab9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 333, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 255, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 231, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 320, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/_zmq.py\", line 1009, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"zmq/backend/cython/_zmq.py\", line 190, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9007')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mptb/Documents/Studia/Data_Science/2_sem/EDT/Project/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Simple Web Application with Flask\n",
    "\n",
    "Aby uruchomić aplikację webową, uruchom plik app.py w terminalu:\n",
    "\n",
    "```bash\n",
    "python app.py\n",
    "```\n",
    "\n",
    "Aplikacja będzie dostępna na http://127.0.0.1:5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
